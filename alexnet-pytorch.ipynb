{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"import required libraries","metadata":{"_uuid":"7c5b21df-771d-4d01-bf2f-28acdd35bc97","_cell_guid":"276d717f-e252-4e5a-897d-c251cb7e6245","trusted":true}},{"cell_type":"code","source":"%matplotlib inline\n#a script from https://github.com/Bjarten/early-stopping-pytorch#:~:text=Early%20stopping%20is%20a%20form,a%20row%20the%20training%20stops.\nfrom early_stopping_script import EarlyStopping\nimport numpy as np\nimport pandas as pd\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np","metadata":{"_uuid":"21675600-43cf-4a37-80b2-3c77f8a15ce6","_cell_guid":"a66bb3a8-b03a-4a36-8b36-6e38bb498df2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-31T11:49:55.443876Z","iopub.execute_input":"2021-12-31T11:49:55.444359Z","iopub.status.idle":"2021-12-31T11:49:57.082736Z","shell.execute_reply.started":"2021-12-31T11:49:55.444271Z","shell.execute_reply":"2021-12-31T11:49:57.081988Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#pipeline to transform images into normalized tensors with mean and std at 0.5 for each\n#color channel (3) for quicker learning\n#resize to 300,300 which is the largest image in the dataset\ntransform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)), \n    transforms.Resize((300,300))]\n)","metadata":{"_uuid":"04c9c76e-106c-455d-b7b4-6f985169438a","_cell_guid":"4884d15e-1cd9-4730-b082-ec889a78d433","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-31T11:50:11.763199Z","iopub.execute_input":"2021-12-31T11:50:11.763504Z","iopub.status.idle":"2021-12-31T11:50:11.771569Z","shell.execute_reply.started":"2021-12-31T11:50:11.763471Z","shell.execute_reply":"2021-12-31T11:50:11.770825Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#create dataset from image files\ntrainset = torchvision.datasets.ImageFolder(\n    root='/kaggle/input/intel-image-classification/seg_train/seg_train', transform=transform)\n#create shuffled indices for splitting into train-val for early stopping\nindices = list(range(len(trainset)))\nnp.random.seed(42)\nnp.random.shuffle(indices)\ntrain_indices, val_indices = indices[:round(len(trainset)*0.9)], indices[round(len(trainset)*0.9):]\n#create samplers\ntrain_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)\nval_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_indices)\n#create dataloaders\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=100,\n                                          num_workers=2,\n                                         sampler=train_sampler)\nvalloader = torch.utils.data.DataLoader(trainset, batch_size=100,\n                                          num_workers=2,\n                                       sampler=val_sampler)","metadata":{"_uuid":"b09bc37f-cde2-4ef7-bdde-114b890e5c60","_cell_guid":"909bbd00-cd5b-4b78-a6d6-c8065a193432","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-31T11:50:19.592470Z","iopub.execute_input":"2021-12-31T11:50:19.592717Z","iopub.status.idle":"2021-12-31T11:50:23.670736Z","shell.execute_reply.started":"2021-12-31T11:50:19.592690Z","shell.execute_reply":"2021-12-31T11:50:23.669991Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#retrieve class names -- imageFolder creates its own labels\nclasses = trainset.class_to_idx\n#create list so that class mapping is easier to access\nclasses = [class_name for (class_name, index) in classes.items()]\nclasses","metadata":{"_uuid":"92b58f34-fdce-4824-af5b-9f89285788b4","_cell_guid":"babb9fce-1288-4abd-b3c4-57e94cfbadc0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-31T11:50:35.324254Z","iopub.execute_input":"2021-12-31T11:50:35.324509Z","iopub.status.idle":"2021-12-31T11:50:35.331645Z","shell.execute_reply.started":"2021-12-31T11:50:35.324480Z","shell.execute_reply":"2021-12-31T11:50:35.330994Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#print a batch of training images to test the dataloader\ndata_iter = iter(trainloader)\nimages, labels = data_iter.next()\n\ndef print_image(image):\n    x = image/2 +0.5 #reverse normalization\n    np_image = x.numpy() #convert to numpy for plt viz\n    plt.imshow(np.transpose(np_image, (1, 2, 0))) #transpose to convert from tensor to numpy\n    \n# show images\nprint_image(torchvision.utils.make_grid(images[:5, :, :]))\n# print labels\nprint(' '.join('%5s' % classes[labels[j]] for j in range(5)))","metadata":{"_uuid":"c32dd682-555c-46dc-a880-d8b3a1dff60e","_cell_guid":"799b3f0d-7867-4222-ba43-e9c616e370f3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-31T11:51:24.051382Z","iopub.execute_input":"2021-12-31T11:51:24.051653Z","iopub.status.idle":"2021-12-31T11:51:25.571428Z","shell.execute_reply.started":"2021-12-31T11:51:24.051620Z","shell.execute_reply":"2021-12-31T11:51:25.570518Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"training and validation dataloader are created. create test dataloader.","metadata":{"_uuid":"7171fa81-9c32-49ca-ad31-de51cca128e2","_cell_guid":"3e7467c2-282c-4b2a-8e13-4e85eaeb11be","trusted":true}},{"cell_type":"code","source":"#load testing image dataset into dataloader\ntestset = torchvision.datasets.ImageFolder(\n    root='/kaggle/input/intel-image-classification/seg_test/seg_test', transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=100,\n                                          shuffle=True, num_workers=2)","metadata":{"_uuid":"6cdc6976-18e6-449a-970b-c1a6230f14af","_cell_guid":"7e8ecaf5-c0ed-4305-8c47-19ff80bc0dee","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-31T11:51:31.762742Z","iopub.execute_input":"2021-12-31T11:51:31.763448Z","iopub.status.idle":"2021-12-31T11:51:32.531854Z","shell.execute_reply.started":"2021-12-31T11:51:31.763402Z","shell.execute_reply":"2021-12-31T11:51:32.531019Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#print a batch of testing images\ndata_iter = iter(testloader)\nimages, labels = data_iter.next()\n    \n# show images\nprint_image(torchvision.utils.make_grid(images[:5, :, :]))\n# print labels\nprint(' '.join('%5s' % classes[labels[j]] for j in range(5)))","metadata":{"_uuid":"b7c077a8-c446-47c5-8740-1c5873e4c639","_cell_guid":"887fe94a-324c-4a87-99af-c44bb089d634","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-31T11:51:39.507814Z","iopub.execute_input":"2021-12-31T11:51:39.508209Z","iopub.status.idle":"2021-12-31T11:51:41.130660Z","shell.execute_reply.started":"2021-12-31T11:51:39.508175Z","shell.execute_reply":"2021-12-31T11:51:41.129429Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"both dataloaders are prepared. create basic CNN.","metadata":{"_uuid":"3d4bf642-a90c-48c0-92f4-530ba27fe93d","_cell_guid":"ad1f2c21-37f7-4a55-a25a-c0604116a0f8","trusted":true}},{"cell_type":"code","source":"class AlexNet(nn.Module):\n    #replicating AlexNet, filter layers from below link\n    #https://www.analyticsvidhya.com/blog/2021/03/introduction-to-the-architecture-of-alexnet/\n    def __init__(self):\n        #initialise inherited methods and properties from nn Module\n        super(AlexNet, self).__init__()\n        #first convolutional layer - 96 filters, 11x11, stride 4\n        self.conv1 = nn.Conv2d(3, 96, 11, stride=4)\n        #max pooling layer - 3x3, stride 2\n        self.max1 = nn.MaxPool2d(3, stride=2)\n        #second convolutional layer - 256 filters, 5x5, stride 1\n        self.conv2 = nn.Conv2d(96, 256, 5)\n        #second max pooling\n        self.max2 = nn.MaxPool2d(3, stride=2)\n        #third conv\n        self.conv3 = nn.Conv2d(256, 384, 3)\n        #fourth conv\n        self.conv4 = nn.Conv2d(384, 384, 3)\n        #fifth conv\n        self.conv5 = nn.Conv2d(384, 256, 3)\n        #max pool 3\n        self.max3 = nn.AdaptiveMaxPool2d(6)\n        #dropout\n        self.drop1 = nn.Dropout(p=0.5)\n        #flatten\n        self.flat = nn.Flatten()\n        #FC1\n        self.full1 = nn.Linear(6*6*256, 4096)\n        #dropout\n        self.drop2 = nn.Dropout(p=0.5)\n        #FC2\n        self.full2 = nn.Linear(4096, 1000) \n        #using 1000 since number of classes is much lower than in original AlexNet\n        \n        #FC3\n        self.full3 = nn.Linear(1000, 6)\n    \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.max1(x)\n        x = F.relu(self.conv2(x))\n        x = self.max2(x)\n        x = F.relu(self.conv3(x))\n        x = F.relu(self.conv4(x))\n        x = F.relu(self.conv5(x))\n        x = self.max3(x)\n        x = self.drop1(x)\n        x = self.flat(x)\n        x = F.relu(self.full1(x))\n        x = self.drop2(x)\n        x = F.relu(self.full2(x))\n        x = self.full3(x)\n        return x","metadata":{"_uuid":"3311cdd6-f95d-42b1-a106-e6f68107b3a7","_cell_guid":"8a60f799-fdf4-4d13-90e7-827c86179c19","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-31T11:51:50.835510Z","iopub.execute_input":"2021-12-31T11:51:50.835836Z","iopub.status.idle":"2021-12-31T11:51:50.849389Z","shell.execute_reply.started":"2021-12-31T11:51:50.835772Z","shell.execute_reply":"2021-12-31T11:51:50.848437Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#create loss function and optimizer\n#initialize CNN\ncnn = AlexNet()\n#cross entropy loss for classification\nlossFunction = nn.CrossEntropyLoss()\n#stochastic gradient descent to converge more quickly using mini batch samples\n#momentum: adds on part of the previous step's gradient to accelerate gradient descent\n#https://paperswithcode.com/method/sgd-with-momentum\noptimizer = optim.SGD(cnn.parameters(), lr=0.001, momentum=0.9)","metadata":{"_uuid":"e5129ff2-6b6f-4348-a247-55e5e6cdc3a1","_cell_guid":"a3d53fe1-9016-4b7b-841b-5ae878e6c6a2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-31T11:51:55.525664Z","iopub.execute_input":"2021-12-31T11:51:55.526244Z","iopub.status.idle":"2021-12-31T11:51:55.897708Z","shell.execute_reply.started":"2021-12-31T11:51:55.526200Z","shell.execute_reply":"2021-12-31T11:51:55.896965Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"cnn","metadata":{"_uuid":"7cc07df8-c116-4e14-a62c-dde38005ae0c","_cell_guid":"047ea1ab-0064-45a6-b193-3b33536c8161","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-31T11:51:58.843123Z","iopub.execute_input":"2021-12-31T11:51:58.843728Z","iopub.status.idle":"2021-12-31T11:51:58.850069Z","shell.execute_reply.started":"2021-12-31T11:51:58.843691Z","shell.execute_reply":"2021-12-31T11:51:58.849323Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#training function\ndef train(cnn, lossFunction, optimizer, trainloader, valloader, max_epochs=50):\n    print('training started')\n    avg_vallosses = []\n    avg_trainlosses = []\n    \n    # initialize the early_stopping object\n    early_stopping = EarlyStopping(verbose=True)\n    \n    for epoch in range(max_epochs):\n        print(f'epoch: {epoch}')\n\n        #training phase, set to training mode so dropout layers work properly\n        cnn.train()\n        train_losses = []\n        \n        #iterate through training batches from data loader\n        for (i, batch) in enumerate(trainloader, 0):\n            #reset gradient of optimizer to 0 to limit gradients to each batch only\n            optimizer.zero_grad()\n            #split into images and labels\n            images, labels = batch\n            #pass batch through CNN\n            output = cnn(images)\n            #get loss\n            loss = lossFunction(output, labels)\n            #backward pass onto parameters\n            loss.backward()\n            #take one step\n            optimizer.step()\n            #add to train_losses list\n            train_losses.append(loss.item())\n        avg_trainloss = np.average(train_losses)\n        \n        #evaluate accuracy based on validation set\n        cnn.eval()\n        val_losses = []\n        with torch.no_grad(): #do not calculate gradients, for inference\n            for data in valloader:\n                images, labels = data\n                output = cnn(images)\n                #get validation loss\n                valloss = lossFunction(output, labels)\n                val_losses.append(valloss.item())\n        \n        #check for early stopping\n        # early_stopping needs the validation loss to check if it has decresed, \n        # and if it has, it will make a checkpoint of the current model\n        avg_valloss = np.average(val_losses)\n        avg_vallosses.append(avg_valloss)\n        \n        early_stopping(avg_valloss, cnn)\n        \n        if early_stopping.early_stop:\n            print(\"Early stopping\")\n            break\n        \n        avg_trainlosses.append(avg_trainloss)\n        print(f'epoch: {epoch+1}, loss: {avg_trainloss}, loss: {avg_valloss}')\n        \n#     load the last checkpoint with the best model\n    cnn.load_state_dict(torch.load('checkpoint.pt'))\n\n    return cnn, avg_trainlosses, avg_vallosses","metadata":{"_uuid":"73180c4c-11cb-4464-9a77-99fdedc8efc1","_cell_guid":"66b63dec-609d-4c63-8ad4-c93467a8fc20","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-31T11:52:16.691351Z","iopub.execute_input":"2021-12-31T11:52:16.691647Z","iopub.status.idle":"2021-12-31T11:52:16.704068Z","shell.execute_reply.started":"2021-12-31T11:52:16.691616Z","shell.execute_reply":"2021-12-31T11:52:16.701639Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T11:52:24.085323Z","iopub.execute_input":"2021-12-31T11:52:24.085641Z","iopub.status.idle":"2021-12-31T11:52:24.101022Z","shell.execute_reply.started":"2021-12-31T11:52:24.085605Z","shell.execute_reply":"2021-12-31T11:52:24.100074Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"device = get_default_device()\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-12-31T11:52:25.500749Z","iopub.execute_input":"2021-12-31T11:52:25.501353Z","iopub.status.idle":"2021-12-31T11:52:25.547102Z","shell.execute_reply.started":"2021-12-31T11:52:25.501315Z","shell.execute_reply":"2021-12-31T11:52:25.546248Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"trainloader = DeviceDataLoader(trainloader, device)\nvalloader = DeviceDataLoader(valloader, device)\ntestloader = DeviceDataLoader(testloader, device)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T11:52:26.831998Z","iopub.execute_input":"2021-12-31T11:52:26.832752Z","iopub.status.idle":"2021-12-31T11:52:26.837568Z","shell.execute_reply.started":"2021-12-31T11:52:26.832706Z","shell.execute_reply":"2021-12-31T11:52:26.836680Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"cnn = to_device(cnn, device)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T11:52:28.614555Z","iopub.execute_input":"2021-12-31T11:52:28.615311Z","iopub.status.idle":"2021-12-31T11:52:31.426666Z","shell.execute_reply.started":"2021-12-31T11:52:28.615269Z","shell.execute_reply":"2021-12-31T11:52:31.425931Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#run training loop\nmodel, avg_trainlosses, avg_vallosses = \\\ntrain(cnn, lossFunction, optimizer, trainloader, valloader)","metadata":{"_uuid":"d6b6da35-22e6-4e54-8acc-d21d6fe93dfe","_cell_guid":"04c4e072-12c8-4113-a109-f09ad521ec66","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-31T11:52:31.428271Z","iopub.execute_input":"2021-12-31T11:52:31.428511Z","iopub.status.idle":"2021-12-31T12:28:23.724242Z","shell.execute_reply.started":"2021-12-31T11:52:31.428478Z","shell.execute_reply":"2021-12-31T12:28:23.722638Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"correct = 0\ntotal = 0\nwith torch.no_grad(): #do not calculate gradients, for inference\n    for data in testloader:\n        images, labels = data\n        outputs = cnn(images)\n        _, predicted = torch.max(outputs.data, 1) #along each example get the max position (the second returned value)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (\n    100 * correct / total))","metadata":{"_uuid":"f1f9d4b5-5623-48c8-80b9-10582303e183","_cell_guid":"6ed64996-fff2-4667-8ddc-b09eb4f7f92a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-31T12:32:38.485183Z","iopub.execute_input":"2021-12-31T12:32:38.485466Z","iopub.status.idle":"2021-12-31T12:32:52.731691Z","shell.execute_reply.started":"2021-12-31T12:32:38.485434Z","shell.execute_reply":"2021-12-31T12:32:52.730884Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"add training curve using cv loss then early stopping function","metadata":{"_uuid":"637d4faf-4f12-426b-a1ce-6f2ab29f6a07","_cell_guid":"b118e115-1435-44de-9241-eb4568f431e2","trusted":true}}]}